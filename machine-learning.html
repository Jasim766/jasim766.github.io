<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Machine Learning | Jasim Alzaabi</title>
  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>
  <header class="hero smaller">
    <div class="container">
      <h1>Machine Learning E-Portfolio</h1>
      <nav class="navbar">
        <a href="index.html">Home</a>
        <a href="about.html">About</a>
        <a href="machine-learning.html" class="active">Machine Learning</a>
        <a href="research-methods.html">Research Methods</a>
      </nav>
    </div>
  </header>

  <section class="section">
    <div class="container">
     <h2>Unit 1 â€“ Introduction to Machine Learning</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit introduced the foundations of machine learning, its role in modern industry, and its socio-technical implications. Key concepts included the categories of ML algorithms (supervised, unsupervised, reinforcement), ethical issues in data-driven decision-making, and the significance of big data in enabling autonomous systems. Discussions emphasized the evolution from Industry 4.0 to the human-centric goals of Industry 5.0.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Initial Discussion Post â€“ I submitted an analysis of the Facebookâ€“Cambridge Analytica incident, highlighting ethical and reputational risks in ML-based profiling. The post connected real-world failure to academic discourse on algorithmic transparency and accountability.
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I explored the historical and current applications of ML, and reflected on the ethical dimensions introduced through the discussion forum.<br />
<strong>SO WHAT:</strong> The Cambridge Analytica case challenged my initial view of ML as a purely technical domain, revealing how societal and ethical failures can arise from poor data governance.<br />
<strong>NOW WHAT:</strong> I intend to integrate ethical awareness (fairness, accountability, transparency) into all future ML projects. This shift in perspective will influence how I approach system design in both academic and professional settings.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
I contributed to my teamâ€™s initial contract by outlining shared expectations, communication channels, and timelines. We agreed to use Slack and Google Docs for all project coordination. I also engaged in the Unit 1 forum and prepared to respond to peer posts in Unit 2.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Discussion forum post (PDF), screenshot of our team charter, and notes from the introductory session â€“ all stored in the shared team drive and referenced in the appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Developed foundational knowledge of machine learning algorithms and their industrial applications</li>
  <li>Gained ethical awareness of data-driven system implications</li>
</ul>

<hr />


<h2>Unit 2 â€“ Exploratory Data Analysis</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit focused on the foundational process of Exploratory Data Analysis (EDA), a critical step in machine learning pipelines. We explored key EDA steps such as data validation, anomaly detection, statistical profiling, and visual pattern recognition. Emphasis was placed on understanding how EDA contributes to effective feature selection and iterative feature engineering.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
For this unit, I created a Jupyter Notebook where I performed EDA on a pre-cleaned customer churn dataset. I applied descriptive statistics, boxplots, and heatmaps to detect multicollinearity and outliers.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit2_eda.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I explored the practical process of EDA using Python libraries like Pandas, Matplotlib, and Seaborn.<br />
<strong>SO WHAT:</strong> I saw how anomalies and data distribution can significantly affect the learning phase and performance of a model.<br />
<strong>NOW WHAT:</strong> Iâ€™ll make EDA a standard step in all future ML pipelines, documenting findings for reproducibility and feature engineering refinement.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Our team aligned on EDA practices during a group call. I shared my notebook and proposed dropping several highly correlated variables, which was adopted by others.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Screenshots of boxplots, correlation matrices, and data distribution charts included in appendix. Notebook hosted on GitHub repo.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Applied statistical and visual techniques for dataset exploration</li>
  <li>Identified feature selection criteria and data integrity risks</li>
</ul>

<hr />


<h2>Unit 3 â€“ Correlation and Regression</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit explored the use of correlation to measure variable relationships, and regression to express those relationships mathematically for prediction. We studied Pearson and Spearman correlation coefficients, and implemented both simple and multiple linear regression models using Python.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Jupyter Notebook demonstrating Pearson, Spearman, simple linear regression, and multiple regression using a housing dataset.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit3_correlation_regression.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I ran statistical tests and built regression models on numeric datasets.<br />
<strong>SO WHAT:</strong> This helped me grasp how correlation analysis feeds directly into regression and feature selection.<br />
<strong>NOW WHAT:</strong> Iâ€™ll incorporate correlation matrices in my future EDA workflows and use regression models to establish performance baselines before advanced ML techniques.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Shared regression visuals and coefficient analysis with my team. Reviewed and provided feedback on another teammateâ€™s interpretation of multicollinearity.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Notebook outputs include regression lines, correlation heatmaps, and residual plots. Notebook and figures stored in GitHub repository.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Built linear models using NumPy, Pandas, and Seaborn</li>
  <li>Interpreted RÂ², p-values, and correlation strength</li>
</ul>

<hr />


<h2>Unit 4 â€“ Linear Regression with Scikit-Learn</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit introduced the use of Scikit-Learn for implementing both simple and multiple linear regression models. Emphasis was placed on preparing input features, training regression models, and evaluating them using RÂ², MAE, and RMSE. We also examined Scikit-Learnâ€™s modular design and how it fits into an end-to-end ML workflow.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Jupyter Notebook on regression modeling with Scikit-Learn using a car price dataset.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit4_linear_regression_scikit.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I used Scikit-Learn to fit and evaluate linear regression models.<br />
<strong>SO WHAT:</strong> I gained practical knowledge of pipeline construction and model validation.<br />
<strong>NOW WHAT:</strong> I will consistently use `train_test_split`, `LinearRegression`, and validation metrics when developing predictive models in real-world scenarios.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Led a short tutorial on Scikit-Learnâ€™s regression module during our weekly team call. I also helped standardize our teamâ€™s approach to evaluating linear models.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Model outputs, RÂ² comparisons, and residual plots documented in GitHub notebook. Code and visual results also shared in team repo.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Used Scikit-Learn to implement linear regression models</li>
  <li>Applied model evaluation techniques (RÂ², MAE, RMSE)</li>
</ul>

<hr />


<h2>Unit 5 â€“ Clustering</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit explored unsupervised learning, focusing on clustering techniques such as k-means and agglomerative clustering. We studied how clustering groups data points based on similarity measures like Euclidean distance and evaluated clustering quality using metrics like SSE and silhouette score. The broader application of clustering in pattern recognition, image analysis, and business intelligence was also covered.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
I completed two visual clustering animations (uniform and custom point sets), then reflected on cluster formation logic in the module wiki. I also created a clustering notebook demonstrating k-means clustering using Scikit-Learn.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit5_clustering.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I applied unsupervised clustering algorithms and evaluated clusters using silhouette scores.<br />
<strong>SO WHAT:</strong> This gave me insight into model-free learning methods, especially the challenge of defining 'optimal' clusters.<br />
<strong>NOW WHAT:</strong> Iâ€™ll explore DBSCAN and hierarchical clustering next and use silhouette analysis for cluster evaluation across future datasets.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
I commented on two peersâ€™ wiki posts, offering alternate interpretations of cluster boundaries. I also shared my notebook on k-means, which a teammate extended with new data features.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Screenshots of animation choices, silhouette graphs, and final clusters are included in appendix. Jupyter Notebook and wiki post are both referenced.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Applied k-means clustering and evaluated with silhouette scoring</li>
  <li>Compared visual vs. algorithmic cluster assessment strategies</li>
</ul>

<hr />

<h2>Unit 6 â€“ Clustering with Python</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit applied the K-Means clustering algorithm using Scikit-Learn on real-life datasets. We explored the use of clustering to reveal patterns in unlabelled data and interpreted clusters through visualisation and inertia/silhouette metrics.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Created a Jupyter Notebook clustering customer data using K-Means. Included elbow plots and cluster interpretation.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit6_kmeans.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I applied clustering on retail data and evaluated the optimal number of clusters.<br />
<strong>SO WHAT:</strong> It helped me see how unsupervised methods can expose structure and user behaviour.<br />
<strong>NOW WHAT:</strong> I aim to explore clustering evaluation in more depth, comparing DBSCAN and GMM models.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
We discussed differences in cluster interpretation. I presented the elbow method and led our visual validation.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Elbow chart, cluster scatter plot and silhouette score visual saved in appendix and GitHub.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Used K-Means for customer segmentation</li>
  <li>Evaluated cluster quality using silhouette score</li>
</ul>

<hr />


<h2>Unit 7 â€“ Introduction to Artificial Neural Networks</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
We explored the structure and function of ANNs, including perceptrons and activation functions. This unit covered biological inspiration, multilayer structures, and their applications across various domains.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Built a simple perceptron, AND gate simulation, and a multi-layer perceptron with sigmoid activation using Python.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit7_ann_intro.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I simulated neural networks from scratch using NumPy.<br />
<strong>SO WHAT:</strong> I grasped the role of non-linear activations in enabling expressive learning.<br />
<strong>NOW WHAT:</strong> Iâ€™ll transition to using frameworks like TensorFlow and PyTorch for more scalable ANN implementations.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Shared logic gate results and discussed pros/cons of sigmoid vs ReLU. Team peer-reviewed activation function performance.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Logic gate screenshots, weight updates, and loss graphs added to appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Simulated basic ANN models from scratch</li>
  <li>Understood forward propagation and activations</li>
</ul>

<hr />


<h2>Unit 8 â€“ Training an Artificial Neural Network</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
We explored training neural networks through backpropagation and weight updates. Key topics included error propagation, gradient descent, and adjusting weights through optimisation.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Extended the MLP implementation from Unit 7 by adding backpropagation, gradient descent visualisation, and ANN error analysis.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit8_ann_training.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> Implemented learning through loss minimisation in neural networks.<br />
<strong>SO WHAT:</strong> Backpropagation revealed how sensitive networks are to hyperparameters.<br />
<strong>NOW WHAT:</strong> I plan to experiment with learning rate schedules and different optimisers like Adam and RMSprop.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
We compared different loss functions and learning rates. I helped visualise error convergence across epochs for the group.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Training logs, loss curves, and annotated backpropagation code in appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Applied backpropagation to train neural networks</li>
  <li>Analysed loss and gradient descent over time</li>
</ul>

<hr />


<h2>Unit 9 â€“ Introduction to Convolutional Neural Networks</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit introduced CNNs, their role in visual recognition, and the architecture of convolutional, pooling, and fully connected layers. We also briefly explored GANs and transformers as emerging deep learning architectures.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Built and tested a basic CNN for digit recognition using a sample image dataset. Modified prediction inputs to observe accuracy.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit9_cnn_object_recognition.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I trained a CNN using Keras and visualised prediction outputs.<br />
<strong>SO WHAT:</strong> CNNs significantly outperformed dense networks on image tasks.<br />
<strong>NOW WHAT:</strong> I plan to explore transfer learning using pre-trained CNNs like VGG16 or ResNet.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Shared model predictions and discussed accuracy drop for misclassified digits. Peer validation of CNN architecture helped refine final layer choices.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Model accuracy logs, prediction visual, and misclassification samples included in appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Implemented convolutional layers and max pooling in Keras</li>
  <li>Diagnosed misclassifications through visual error analysis</li>
</ul>

<hr />


<h2>Unit 10 â€“ Natural Language Processing (NLP)</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit introduced transformer-based NLP models (BERT, GPT, T5) and their role in text processing, summarisation, and generation. We explored evaluation metrics such as BLEU and ROUGE, and discussed the influence of self-supervised learning in scaling NLP applications.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Fine-tuned a pretrained BERT model for sentiment classification. Evaluated performance using F1-score and confusion matrix.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit10_nlp_transformers.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I applied transfer learning in NLP using HuggingFaceâ€™s `transformers` library.<br />
<strong>SO WHAT:</strong> This showed the impact of pretraining and contextual embeddings.<br />
<strong>NOW WHAT:</strong> I aim to evaluate larger models like T5 and experiment with summarisation and Q&A pipelines.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Collaborated on fine-tuning datasets and tokenizer choices. Exchanged feedback on performance metrics and label imbalance.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Confusion matrix, tokenizer output, and training log screenshots available in appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Applied BERT for sentiment classification</li>
  <li>Evaluated NLP models using precision, recall, and BLEU score</li>
</ul>

<hr />


<h2>Unit 11 â€“ Model Selection and Evaluation</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This unit covered hyperparameter tuning, cross-validation, and evaluation metrics beyond accuracy (e.g., AUC, F1, Precision/Recall). It introduced MLOps principles such as reproducibility, model deployment, and performance monitoring in production.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Ran `model_Performance_Measurement.ipynb` and compared AUC and RÂ² across multiple model types and parameter settings.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit11_model_selection.ipynb" target="_blank">View on GitHub</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I tuned hyperparameters and monitored impact on key evaluation metrics.<br />
<strong>SO WHAT:</strong> This helped me see how choice of metric changes model evaluation focus.<br />
<strong>NOW WHAT:</strong> I aim to build automated evaluation pipelines as part of an MLOps workflow.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Led a GitHub issue discussion around cross-validation split strategy. Peer-reviewed ROC curve plots and helped clarify misinterpretations.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Evaluation score tables, AUC-ROC curve plots, and parameter impact charts added in appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Applied hyperparameter tuning and performance monitoring</li>
  <li>Explored MLOps principles and metric-based model evaluation</li>
</ul>

<hr />


<h2>Unit 12 â€“ Industry 4.0 and Machine Learning</h2>

<h4>ğŸ§  Summary of Learning</h4>
<p>
This final unit examined the convergence of machine learning with Industry 4.0 trends: digital twins, Edge AI, self-supervised learning, and neural architecture search. It also introduced the vision of Industry 5.0â€”human-centric and sustainable AI.
</p>

<h4>ğŸ“ Artefact</h4>
<p>
Wrote a wiki post discussing the role of Self-Supervised Learning and Edge AI in autonomous manufacturing systems.  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit12_industry4.0_reflection.md" target="_blank">View Wiki Post</a>
</p>

<h4>ğŸª Reflection (WHAT â†’ SO WHAT â†’ NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> Explored how ML is driving automation and AI-driven systems across industries.<br />
<strong>SO WHAT:</strong> I now see ML not just as a technical skill but a socio-technical force.<br />
<strong>NOW WHAT:</strong> I aim to explore applications in AI for sustainability, energy efficiency, and smart healthcare.
</p>

<h4>ğŸ¤ Collaboration</h4>
<p>
Engaged in discussions on the ethical use of autonomous AI. Shared readings on bias in facial recognition and contributed to the digital twin case study.
</p>

<h4>ğŸ“¸ Evidence</h4>
<p>
Screenshots of wiki contribution and reading annotations included in appendix.
</p>

<h4>ğŸ› ï¸ Skills & Competencies</h4>
<ul>
  <li>Connected ML concepts to industry-wide transformations</li>
  <li>Reflected on ethical, legal, and social implications of AI</li>
</ul>

<hr />

      <h4>ğŸ“š References</h4>
      <p>[Add APA/Harvard formatted sources used across all units and reflection]</p>
    </div>
  </section>

  <footer>
    <div class="container">
      <p>Â© 2025 Jasim Alzaabi</p>
    </div>
  </footer>
</body>
</html>
