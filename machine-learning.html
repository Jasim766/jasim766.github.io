<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Machine Learning | Jasim Alzaabi</title>
  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>
  <header class="hero smaller">
    <div class="container">
      <h1>Machine Learning E-Portfolio</h1>
      <nav class="navbar">
        <a href="index.html">Home</a>
        <a href="about.html">About</a>
        <a href="machine-learning.html" class="active">Machine Learning</a>
        <a href="research-methods.html">Research Methods</a>
      </nav>
    </div>
  </header>

  <section class="section">
    <div class="container">
      <h2>Unit 1 – Introduction to Machine Learning</h2>

<h4>🧠 Summary of Learning</h4>
<p>This unit introduced the foundations of machine learning, its role in modern industry, and its socio-technical implications. Key concepts included the categories of ML algorithms (supervised, unsupervised, reinforcement), ethical issues in data-driven decision-making, and the significance of big data in enabling autonomous systems. Discussions emphasized the evolution from Industry 4.0 to the human-centric goals of Industry 5.0.</p>

<h4>📁 Artefact</h4>
<p>Initial Discussion Post – I submitted an analysis of the Facebook–Cambridge Analytica incident, highlighting ethical and reputational risks in ML-based profiling. The post connected real-world failure to academic discourse on algorithmic transparency and accountability.</p>

<h4>🪞 Reflection (WHAT → SO WHAT → NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I explored the historical and current applications of ML, and reflected on the ethical dimensions introduced through the discussion forum.<br />
<strong>SO WHAT:</strong> The Cambridge Analytica case challenged my initial view of ML as a purely technical domain, revealing how societal and ethical failures can arise from poor data governance.<br />
<strong>NOW WHAT:</strong> I intend to integrate ethical awareness (fairness, accountability, transparency) into all future ML projects. This shift in perspective will influence how I approach system design in both academic and professional settings.
</p>

<h4>🤝 Collaboration</h4>
<p>I contributed to my team’s initial contract by outlining shared expectations, communication channels, and timelines. We agreed to use Slack and Google Docs for all project coordination. I also engaged in the Unit 1 forum and prepared to respond to peer posts in Unit 2.</p>

<h4>📸 Evidence</h4>
<p>Discussion forum post (PDF), screenshot of our team charter, and notes from the introductory session – all stored in the shared team drive and referenced in the appendix.</p>

<h4>🛠️ Skills & Competencies</h4>
<ul>
  <li>Developed foundational knowledge of machine learning algorithms and their industrial applications</li>
  <li>Gained ethical awareness of data-driven system implications</li>
</ul>

<hr />


      <!-- Repeat the following block for Units 2 to 12 -->

      <h2>Unit 2 – Exploratory Data Analysis</h2>

<h4>🧠 Summary of Learning</h4>
<p>
This unit focused on the foundational process of Exploratory Data Analysis (EDA), a critical step in machine learning pipelines. We explored key EDA steps such as data validation, anomaly detection, statistical profiling, and visual pattern recognition. Emphasis was placed on understanding how EDA contributes to effective feature selection and iterative feature engineering. Through the lens of both theoretical and practical examples, we gained a clearer view of how data integrity directly impacts downstream ML models.
</p>

<h4>📁 Artefact</h4>
<p>
For this unit, I created a Jupyter Notebook where I performed EDA on a pre-cleaned customer churn dataset. I applied descriptive statistics, boxplots, and heatmaps to detect multicollinearity and outliers. This practical artefact was part of our team’s preparation for model development. The file has been uploaded to our shared repository and referenced in the appendix.
</p>

<h4>🪞 Reflection (WHAT → SO WHAT → NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I explored the practical process of EDA using Python libraries like Pandas, Matplotlib, and Seaborn. Key insights were gained through hands-on application, particularly on detecting data skew and feature redundancy.<br />
<strong>SO WHAT:</strong> The act of cleaning and visually inspecting the dataset taught me how underlying anomalies can distort ML performance. It also highlighted the iterative nature of ML workflows — where EDA informs feature engineering and vice versa.<br />
<strong>NOW WHAT:</strong> In future projects, I’ll treat EDA not just as a preparatory step, but as a discovery process that helps build context-aware, efficient models. I’ll also document each EDA step carefully to support reproducibility.
</p>

<h4>🤝 Collaboration</h4>
<p>
Our team held a mid-week Zoom call to align on EDA approaches and discuss feature relevance across different model types. I presented my visual findings and suggested removing several correlated fields before model training. The team agreed, and my Jupyter Notebook was used as a base template for others.
</p>

<h4>📸 Evidence</h4>
<p>
Screenshots of heatmaps, summary statistics, and correlation matrices are included in the appendix. The original Jupyter file is available in the shared team GitHub repo.
</p>

<h4>🛠️ Skills & Competencies</h4>
<ul>
  <li>Applied statistical summaries and visual analysis using Pandas and Seaborn</li>
  <li>Developed collaborative EDA workflow in a team context with shared datasets</li>
</ul>

<hr />

      <h2>Unit 3 – Correlation and Regression</h2>

<h4>🧠 Summary of Learning</h4>
<p>
This unit covered two essential statistical tools used in machine learning and data science — correlation and regression. Correlation measures the strength and direction of linear relationships between variables, while regression provides a predictive model to understand how the dependent variable changes with one or more independent variables. This unit emphasized their role in exploratory analysis and model diagnostics, offering hands-on practice in computing and interpreting both.
</p>

<h4>📁 Artefact</h4>
<p>
For this unit, I created a Jupyter Notebook that demonstrates Pearson correlation, Spearman rank correlation, simple linear regression, and multiple linear regression using a housing price dataset. Each technique is visualized using scatter plots and line fits, with interpretations included. The notebook has been uploaded to GitHub and is available here:  
<a href="https://github.com/your-username/ml-eportfolio/blob/main/unit3_correlation_regression.ipynb" target="_blank">View Jupyter Notebook on GitHub</a>
</p>

<h4>🪞 Reflection (WHAT → SO WHAT → NOW WHAT)</h4>
<p>
<strong>WHAT:</strong> I explored how correlation can identify multicollinearity, and how regression can model outcome variables. I learned to compute coefficients and interpret R² values.<br />
<strong>SO WHAT:</strong> This reinforced my understanding of how foundational statistics underpin ML models, particularly linear regression’s role in baseline modeling and feature interpretation.<br />
<strong>NOW WHAT:</strong> I will apply these techniques in future preprocessing stages to evaluate feature relevance and redundancy. I also plan to integrate correlation matrices into my EDA process routinely.
</p>

<h4>🤝 Collaboration</h4>
<p>
During our team sync, I shared insights on overfitting in multiple regression and emphasized checking variance inflation factors (VIF). I reviewed a teammate’s notebook and gave feedback on graph labeling and interpretation, which they incorporated into the shared repo.
</p>

<h4>📸 Evidence</h4>
<p>
Notebook screenshots, regression plots, and correlation matrices are included in the appendix. The GitHub repository link to the notebook serves as a primary artefact.
</p>

<h4>🛠️ Skills & Competencies</h4>
<ul>
  <li>Implemented and interpreted linear regression models in Python</li>
  <li>Visualized and analyzed correlations using scatter plots and heatmaps</li>
</ul>

<hr />


      <h2>Unit 4 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 5 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 6 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 7 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 8 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 9 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 10 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 11 – [Unit Title]</h2>
      <p>Coming soon...</p>

      <h2>Unit 12 – Final Submission & Reflection</h2>
      <h4>📽️ Final Reflection (Max 1000 Words)</h4>
      <p>[Structured reflection using Rolfe et al. (2001): WHAT → SO WHAT → NOW WHAT]</p>

      <h4>📚 References</h4>
      <p>[Add APA/Harvard formatted sources used across all units and reflection]</p>
    </div>
  </section>

  <footer>
    <div class="container">
      <p>© 2025 Jasim Alzaabi</p>
    </div>
  </footer>
</body>
</html>
